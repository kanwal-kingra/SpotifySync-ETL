{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 5.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom awsglue.dynamicframe import DynamicFrame\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.7 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 5.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 5\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 5\nIdle Timeout: 2880\nSession ID: ce9a2fee-acc0-4766-99c4-bd4007e94f49\nApplying the following default arguments:\n--glue_kernel_version 1.0.7\n--enable-glue-datacatalog true\nWaiting for session ce9a2fee-acc0-4766-99c4-bd4007e94f49 to get into ready status...\nSession ce9a2fee-acc0-4766-99c4-bd4007e94f49 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql.functions import explode, col, to_date\nfrom datetime import datetime",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "s3_path = 's3://soptify-etl-project-kkk/raw_data/to_be_processed/spotify_raw_2025-01-05 16:22:15.181294.json'\nsource_dyf = glueContext.create_dynamic_frame_from_options(\n    connection_type = 's3',\n    connection_options = {'paths':[s3_path]},\n    format = 'json'\n)\n# source_dyf.show()\nspotify_df = source_dyf.toDF()\nspotify_df.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------------------+-----+----+------+--------+-----+\n|                href|               items|limit|next|offset|previous|total|\n+--------------------+--------------------+-----+----+------+--------+-----+\n|https://api.spoti...|[{2024-02-23T14:5...|  100|NULL|     0|    NULL|   62|\n+--------------------+--------------------+-----+----+------+--------+-----+\n\n/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def process_albums(spotify_df):\n    df_album = spotify_df.withColumn('items', explode('items')).select(\n        col('items.track.album.id').alias('album_id'),\n        col('items.track.album.name').alias('album_name'),\n        col('items.track.album.release_date').alias('release_date'),\n        col('items.track.album.total_tracks').alias('total_tracks'),\n        col('items.track.album.external_urls.spotify').alias('url')\n        ).drop_duplicates(['album_id'])\n    return df_album\n\ndef process_artists(spotify_df):\n    df_artist_exploded = spotify_df.select(explode(col('items')).alias('item')).select(explode(col('item.track.artists')).alias('artist'))\n    df_artists = df_artist_exploded.select(\n        col('artist.id').alias('artist_id'),\n        col('artist.name').alias('artist_name'),\n        col('artist.external_urls.spotify').alias('external_url')\n        ).drop_duplicates(['artist_id'])\n    return df_artists\n\ndef process_songs(spotify_df):\n    df_explode = spotify_df.select(explode(col('items')).alias('item'))\n    df_songs = df_explode.select(\n        col('item.track.id').alias('song_id'),\n        col('item.track.name').alias('song_name'),\n        col('item.track.duration_ms').alias('duration_ms'),\n        col('item.track.external_urls.spotify').alias('url'),\n        col('item.track.popularity').alias('popularity'),\n        col('item.added_at').alias('song_added'),\n        col('item.track.album.id').alias('album_id'),\n        col('item.track.artists')[0]['id'].alias('artist_id')\n        ).drop_duplicates(['song_id'])\n    df_songs = df_songs.withColumn('song_added', to_date(col('song_added')))\n    return df_songs\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 30,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "album_df = process_albums(spotify_df)\nalbum_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------------------+------------+------------+--------------------+\n|            album_id|          album_name|release_date|total_tracks|                 url|\n+--------------------+--------------------+------------+------------+--------------------+\n|03GXBC2T6YdaBZo75...|Montagem Sonic Ri...|  2024-05-15|           1|https://open.spot...|\n|06a7H7nusNMvM7yL8...|                AURA|  2024-07-12|           3|https://open.spot...|\n|09xRsRc7pX399wCGE...|      BRUXO FANTASMA|  2024-08-16|           4|https://open.spot...|\n|0TwAp1jAUFp1PQtdD...|              GHOST!|  2022-12-02|           1|https://open.spot...|\n|0ZE5fMneYtdl93X1G...|            BYE BYE!|  2024-01-12|           3|https://open.spot...|\n+--------------------+--------------------+------------+------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "artist_df = process_artists(spotify_df)\nartist_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+------------+--------------------+\n|           artist_id| artist_name|        external_url|\n+--------------------+------------+--------------------+\n|07MaeHw0cyfmgQ9D9...|DJ JEEAN 011|https://open.spot...|\n|09cKncAQn28NqTUOR...|       Ariis|https://open.spot...|\n|0H942IkjXv9bjx5Ox...|      jnhygs|https://open.spot...|\n|0T82thOoh3ksJmLJv...|     dawnicy|https://open.spot...|\n|0ayuHZiwRQ5jXBaGG...|      DJ RIO|https://open.spot...|\n+--------------------+------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "song_df = process_songs(spotify_df)\nsong_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 31,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------------------+--------------------+-----------+--------------------+----------+----------+--------------------+--------------------+\n|             song_id|           song_name|duration_ms|                 url|popularity|song_added|            album_id|           artist_id|\n+--------------------+--------------------+-----------+--------------------+----------+----------+--------------------+--------------------+\n|02WKo37gebkkQKor2...|Beeper Funk - Slowed|     103375|https://open.spot...|        71|2024-10-10|5eEfzNcFaXPsBXJzk...|648ZoUpTM6iIMTCgo...|\n|02oUvHd9QhVUO4YYb...|METAMORPHOSIS - S...|     172219|https://open.spot...|        63|2024-10-07|4z0nL9bblVphvhmt8...|5hKGLu4Ik88FzWcTP...|\n|0G17UriYHMjXnZE2O...|SUNRISE (Slowed +...|     138857|https://open.spot...|        67|2025-01-01|2tiHE58yMuZI1wiyg...|2rgcNuLkn8pPBdKZh...|\n|0RgKtaVv27Nff2y29...|           ICEWHORE!|      79052|https://open.spot...|        68|2024-05-15|5J00ADHG1jlJiLjQD...|1TTHC3GlNDaE5eVoC...|\n|0iaa1DkqOki4FFGq3...|X-SLIDE - Ultra S...|     126129|https://open.spot...|        71|2024-09-27|1QFKbF3Oot9Ad1NnR...|2vPnS0IpayC2RVFuQ...|\n+--------------------+--------------------+-----------+--------------------+----------+----------+--------------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def write_to_s3(df, path_suffix, format_type='csv'):\n    dynamic_frame = DynamicFrame.fromDF(df, glueContext, 'dynamic_frame')\n\n    glueContext.write_dynamic_frame.from_options(\n        frame = dynamic_frame,\n        connection_type = 's3',\n        connection_options = {'path' : f's3://soptify-etl-project-kkk/transformed_data/{path_suffix}/'},\n        format = format_type)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "write_to_s3(album_df, 'album/album_transformed_{}'.format(datetime.now().strftime('%Y-%m-%d')), 'csv')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "write_to_s3(artist_df, 'artist/artist_transformed_{}'.format(datetime.now().strftime('%Y-%m-%d')), 'csv')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "write_to_s3(song_df, 'song/song_transformed_{}'.format(datetime.now().strftime('%Y-%m-%d')), 'csv')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 32,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "#album_df.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": []
		}
	]
}